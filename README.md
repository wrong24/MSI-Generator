# MSI Generator

> High-fidelity multispectral image generation using a Swin-U-Net model. Converts RGB images into 6-channel multispectral outputs through an interactive UI and scalable API.

---

## ğŸš€ Features

- ğŸ¯ **High-Fidelity Conversion**  
  Generate accurate 6-channel multispectral images using a Swin-U-Net model.

- ğŸ–¼ï¸ **Interactive Web UI**  
  Built with Streamlit for easy image upload and output visualization.

- âš™ï¸ **Scalable FastAPI Backend**  
  Dockerized REST API serving the PyTorch model with CPU or GPU support.

- ğŸ§© **Large Image Support**  
  Automatically tiles large images into 224Ã—224 patches and stitches outputs.

- ğŸ§± **Modular Codebase**  
  Cleanly separated modules for training, inference, and deployment.

---

## ğŸ—ï¸ Architecture Overview

Frontend (Streamlit)
â‡… REST API
Backend (FastAPI + PyTorch model)


- **Frontend (`frontend_app/`)**  
  Uploads images, handles patching, calls the backend, and displays output.

- **Backend (`model_api/`)**  
  Hosts the deep learning model and performs patch-wise inference.

---

## ğŸ§° Tech Stack

| Layer     | Tools                           |
|-----------|----------------------------------|
| Model     | PyTorch, Timm (Swin Transformer) |
| Backend   | FastAPI, Uvicorn                 |
| Frontend  | Streamlit                        |
| Container | Docker                           |
| Versioning | Git                             |

---

## âš™ï¸ Prerequisites

Ensure the following are installed:

- Python 3.9+
- pip
- Docker + Docker Compose
- Git

---

## ğŸ“¦ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/wrong24/MSIGenerator.git
cd MSIGenerator
```

### 2. Add the Pre-trained Model
The pre-trained model best_generator.pth is not included due to file size.

You can either:

Train your own (see Training)

Or download it and place it like this:

MSIGenerator/
â””â”€â”€ model_api/
    â””â”€â”€ best_generator.pth
    
â–¶ï¸ Running the Application
1ï¸âƒ£ Start the Backend (FastAPI + Docker)
```bash
cd model_api/
```

# Build Docker image
docker build -t msi-generator-api .

# Run with CPU
docker run -d -p 8000:8000 --name msi_api msi-generator-api

# Or run with GPU (requires NVIDIA runtime)
docker run -d --gpus all -p 8000:8000 --name msi_api msi-generator-api
Visit: http://localhost:8000
You should see:

{"status": "MSI Generation API is running."}
2ï¸âƒ£ Start the Frontend (Streamlit)
```bash
cd frontend_app/
```

# Optional: Setup virtual environment
python -m venv venv
source venv/bin/activate      # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run app.py
Visit: http://localhost:8501

ğŸ§  Training a New Model
You can train a model on your own multispectral dataset.

1. Prepare Dataset
Organize your dataset as expected in dataset.py

Set the correct path in config.py via DATASET_ROOT_PATH

2. Adjust Training Config
Edit config.py to modify:

NUM_EPOCHS

BATCH_SIZE

LEARNING_RATE

Any other hyperparameters

3. Run Training
```bash
python train.py
```
The best model is saved as best_generator.pth.
Move it to the model_api/ folder to use it with the API.

ğŸ“ Project Structure
```arduino
MSIGenerator/
â”œâ”€â”€ model_api/
â”‚   â”œâ”€â”€ best_generator.pth
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend_app/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ model_training/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ dataset.py
â””â”€â”€ README.md
```
